{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Palo Alto data merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Chargerpoint data merge\n",
    "Get names of all xlsx files in folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/ar/Google/DTU/Courses/Advanced business analytics/ABA - Project /Datasets/Palo_Alto/CY21Q3 EV Charging Event Data.xlsx', '/home/ar/Google/DTU/Courses/Advanced business analytics/ABA - Project /Datasets/Palo_Alto/CY23Q2 EV Charging Event Data.xlsx', '/home/ar/Google/DTU/Courses/Advanced business analytics/ABA - Project /Datasets/Palo_Alto/CY21Q1 EV Charging Event Data.xlsx', '/home/ar/Google/DTU/Courses/Advanced business analytics/ABA - Project /Datasets/Palo_Alto/CY23Q4 EV Charging Event Data.xlsx', '/home/ar/Google/DTU/Courses/Advanced business analytics/ABA - Project /Datasets/Palo_Alto/CY21Q4 EV Charging Event Data.xlsx', '/home/ar/Google/DTU/Courses/Advanced business analytics/ABA - Project /Datasets/Palo_Alto/CY23Q1 EV Charging Event Data.xlsx', '/home/ar/Google/DTU/Courses/Advanced business analytics/ABA - Project /Datasets/Palo_Alto/CY22Q4 EV Charging Event Data.xlsx', '/home/ar/Google/DTU/Courses/Advanced business analytics/ABA - Project /Datasets/Palo_Alto/CY22Q3 EV Charging Event Data.xlsx', '/home/ar/Google/DTU/Courses/Advanced business analytics/ABA - Project /Datasets/Palo_Alto/CY22Q1 EV Charging Event Data.xlsx', '/home/ar/Google/DTU/Courses/Advanced business analytics/ABA - Project /Datasets/Palo_Alto/CY22Q2 EV Charging Event Data.xlsx', '/home/ar/Google/DTU/Courses/Advanced business analytics/ABA - Project /Datasets/Palo_Alto/CY23Q3 EV Charging Event Data.xlsx', '/home/ar/Google/DTU/Courses/Advanced business analytics/ABA - Project /Datasets/Palo_Alto/CY21Q2 EV Charging Event Data.xlsx']\n"
     ]
    }
   ],
   "source": [
    "path =r'/home/ar/Google/DTU/Courses/Advanced business analytics/ABA - Project /Datasets/Palo_Alto'#path of stored xlsx files\n",
    "filenames = glob.glob(path + \"/*.xlsx\")\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiallize empty dataframe and concatenate all files from 2021 onwards, store into a new csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    data = pd.read_excel(i)\n",
    "    df = pd.concat([df, data])\n",
    "\n",
    "# Create a csv file with only chargerpoint chargers from 2021 to 2023\n",
    "df.to_csv('updated_till_2024_chargerpoint', index=False)  # Set index=False to exclude the index column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the csv files corresponding to before 2021 and after, mege both csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15998/3669125881.py:1: DtypeWarning: Columns (29,30,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  before = pd.read_csv('/home/ar/Google/DTU/Courses/Advanced business analytics/ABA - Project /Datasets/Palo_Alto/EVChargingStationUsage.csv') # Path to old palo alto dataset\n",
      "/tmp/ipykernel_15998/3669125881.py:2: DtypeWarning: Columns (30,31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  after = pd.read_csv('/home/ar/Google/DTU/Courses/Advanced business analytics/ABA - Project /Datasets/Palo_Alto/updated_till_2024_chargerpoint')# Path to concatenated chargerpoint paloalto dataset in previous cell\n"
     ]
    }
   ],
   "source": [
    "before = pd.read_csv('/home/ar/Google/DTU/Courses/Advanced business analytics/ABA - Project /Datasets/Palo_Alto/EVChargingStationUsage.csv') # Path to old palo alto dataset\n",
    "after = pd.read_csv('/home/ar/Google/DTU/Courses/Advanced business analytics/ABA - Project /Datasets/Palo_Alto/updated_till_2024_chargerpoint')# Path to concatenated chargerpoint paloalto dataset in previous cell\n",
    "\n",
    "together=pd.DataFrame()\n",
    "\n",
    "together = pd.concat([before, after])\n",
    "# Create a csv file with only chargerpoint chargers from 2011 to 2023\n",
    "together.to_csv('updated_till_24_only_charger_point', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Flexpoint data reformatting\n",
    "Get the list of all files  from 22 onwards which contain the new types of chargers with new format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/ar/Google/DTU/Courses/Advanced business analytics/ABA - Project /Datasets/Palo_Alto/CY23Q2 EV Charging Event Data.xlsx', '/home/ar/Google/DTU/Courses/Advanced business analytics/ABA - Project /Datasets/Palo_Alto/CY23Q4 EV Charging Event Data.xlsx', '/home/ar/Google/DTU/Courses/Advanced business analytics/ABA - Project /Datasets/Palo_Alto/CY23Q1 EV Charging Event Data.xlsx', '/home/ar/Google/DTU/Courses/Advanced business analytics/ABA - Project /Datasets/Palo_Alto/CY22Q4 EV Charging Event Data.xlsx', '/home/ar/Google/DTU/Courses/Advanced business analytics/ABA - Project /Datasets/Palo_Alto/CY22Q3 EV Charging Event Data.xlsx', '/home/ar/Google/DTU/Courses/Advanced business analytics/ABA - Project /Datasets/Palo_Alto/CY22Q1 EV Charging Event Data.xlsx', '/home/ar/Google/DTU/Courses/Advanced business analytics/ABA - Project /Datasets/Palo_Alto/CY22Q2 EV Charging Event Data.xlsx', '/home/ar/Google/DTU/Courses/Advanced business analytics/ABA - Project /Datasets/Palo_Alto/CY23Q3 EV Charging Event Data.xlsx']\n"
     ]
    }
   ],
   "source": [
    "new_chargers=[]\n",
    "for file in filenames:\n",
    "    if '22' in file or '23' in file:\n",
    "        new_chargers.append(file)\n",
    "    else:\n",
    "        continue\n",
    "print(new_chargers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and store into single pandas dataframe all excel sheets containing complete data on Powerflex charger(that is from 2022q1 onwards) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for i in new_chargers:\n",
    "    data = pd.read_excel(i, sheet_name='Powerflex')\n",
    "    df = pd.concat([df, data])\n",
    "    \n",
    "df.to_csv('only_powerflex_22_onwards', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data from both chargepoint format and flexpoint format, to see which ones need to be dropped, reformatted..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['10-digit session UID', 'Session ID', 'Session start', 'Session end',\n",
      "       'Session duration (minutes)', 'Charging duration (minutes)',\n",
      "       'Session idle (minutes)', 'Estimated Completion Time', 'kWh delivered',\n",
      "       'MAX kW', 'AVG kW', 'SoC Start', 'SoC End', 'User', 'Vehicle',\n",
      "       'EVSE Status', 'EVSEID (PFID)', 'FSE ID', 'XB Address', 'Serial #',\n",
      "       'EVSE type', 'Parking Space', 'Site', 'Site Location', 'Cost to site',\n",
      "       'Cost to driver', 'Fleet', 'Session Idle (minutes)', 'Space #',\n",
      "       'Session start month', 'Session start day', 'Session start hour',\n",
      "       'Session start day of week', 'Session start time', 'Session end month',\n",
      "       'Session end day', 'Session end hour', 'Session end day of week',\n",
      "       'Session end time'],\n",
      "      dtype='object')\n",
      "Index(['Station Name', 'MAC Address', 'Org Name', 'Start Date',\n",
      "       'Start Time Zone', 'End Date', 'End Time Zone',\n",
      "       'Transaction Date (Pacific Time)', 'Total Duration (hh:mm:ss)',\n",
      "       'Charging Time (hh:mm:ss)', 'Energy (kWh)', 'GHG Savings (kg)',\n",
      "       'Gasoline Savings (gallons)', 'Port Type', 'Port Number', 'Plug Type',\n",
      "       'EVSE ID', 'Address 1', 'City', 'State/Province', 'Postal Code',\n",
      "       'Country', 'Latitude', 'Longitude', 'Currency', 'Fee', 'Ended By',\n",
      "       'Plug In Event Id', 'Driver Postal Code', 'User ID', 'County',\n",
      "       'System S/N', 'Model Number', 'Address 2', 'Driver Name',\n",
      "       'Driver Account No.', 'Start SOC', 'End SOC', 'Transaction ID',\n",
      "       'Drive Name'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "flexpoint= df.copy()\n",
    "charegerpoint = together.copy()\n",
    "\n",
    "print(flexpoint.columns)\n",
    "print(charegerpoint.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge columns 'Parking Space' and 'Site Location' to get unique charger name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flexpoint[\"Station Name\"] = flexpoint[\"Site Location\"] + flexpoint[\"Parking Space\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two new columns containing the longitude and latitude coordinates from the adress(conatained in 'Site Location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import numpy\n",
    "geolocator = Nominatim(user_agent=\"ba_project\") # Initialize Nominatim API\n",
    "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)# Using rate limiter to respect usage policy\n",
    "\n",
    "# With this policy limiter it will take ages to apply the function to all rows, therefore get unique adress values and just apply fucntion to these\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1213 Newell Rd, Palo Alto, CA 94303'\n",
      " '520 Webster St, Palo Alto, CA 94301'\n",
      " '445 Bryant St, Palo Alto, CA 94301'\n",
      " '250 Hamilton Ave Palo Alto, CA 94301'\n",
      " '1451 Middlefield Rd, Palo Alto, CA 94301'\n",
      " '3700 Middlefield Rd, Palo Alto, CA 94303'\n",
      " '445 Bryant St Palo Alto, CA 94301' '520 Webster St Palo Alto, CA 94301'\n",
      " nan]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "unique_values = flexpoint['Site Location'].unique()\n",
    "print(unique_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1213 Newell Rd, Palo Alto, CA 94303': (37.4449757, -122.13907277496439), '520 Webster St, Palo Alto, CA 94301': (37.44924881470433, -122.15774617516509), '445 Bryant St, Palo Alto, CA 94301': (37.44649759802612, -122.16239223435413), '250 Hamilton Ave Palo Alto, CA 94301': (37.444848, -122.160466), '1451 Middlefield Rd, Palo Alto, CA 94301': (37.4434284, -122.14442820519255), '3700 Middlefield Rd, Palo Alto, CA 94303': (37.4221875, -122.1131623), '445 Bryant St Palo Alto, CA 94301': (37.44649759802612, -122.16239223435413), '520 Webster St Palo Alto, CA 94301': (37.44924881470433, -122.15774617516509), nan: (46.3144754, 11.0480288)}\n"
     ]
    }
   ],
   "source": [
    "location_dict={}#empty dictionary for mapping of adress to lat/long\n",
    "for adress in unique_values:\n",
    "    location =geocode(adress)\n",
    "    if location:\n",
    "        vals= location.latitude, location.longitude\n",
    "    else:\n",
    "        vals= np.nan, np.nan    \n",
    "    location_dict[adress]= vals\n",
    "    \n",
    "print(location_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two new columns in flexpoint dataframe with Latitude and Longitude information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the latitude and longitude to new columns in the DataFrame\n",
    "flexpoint['Latitude'] = flexpoint['Site Location'].map(lambda x: location_dict[x][0])\n",
    "flexpoint['Longitude'] = flexpoint['Site Location'].map(lambda x: location_dict[x][1])\n",
    "#error handling\n",
    "flexpoint['Latitude'] = flexpoint['Site Location'].map(lambda x: location_dict.get(x, (None, None))[0])\n",
    "flexpoint['Longitude'] = flexpoint['Site Location'].map(lambda x: location_dict.get(x, (None, None))[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dicctionary for new columns name assignation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping={\n",
    "    '10-digit session UID': 'drop', \n",
    "    'Session ID': 'Plug In Event Id',\n",
    "    'Session start':'Start Date',\n",
    "    'Session end': 'End Date',\n",
    "    'Session duration (minutes)': 'Total Duration (hh:mm:ss)', \n",
    "    'Charging duration (minutes)': 'Charging Time (hh:mm:ss)',\n",
    "    'Session idle (minutes)': 'drop', \n",
    "    'Estimated Completion Time': 'drop', \n",
    "    'kWh delivered': 'Energy (kWh)',\n",
    "    'MAX kW': 'drop', \n",
    "    'AVG kW': 'drop', \n",
    "    'SoC Start': 'Start SOC', \n",
    "    'SoC End': 'End SOC', \n",
    "    'User': 'User ID', \n",
    "    'Vehicle': 'drop',\n",
    "    'EVSE Status': 'drop', \n",
    "    'EVSEID (PFID)': 'drop', \n",
    "    'FSE ID': 'drop', \n",
    "    'XB Address': 'drop', \n",
    "    'Serial #': 'drop',\n",
    "    'EVSE type':'drop', \n",
    "    'Parking Space': 'drop', \n",
    "    'Site': 'drop', \n",
    "    #'Station Name': 'Station Name',\n",
    "    'Site Location': 'Address 1', \n",
    "    'Cost to site': 'drop',\n",
    "    'Cost to driver': 'drop', \n",
    "    'Fleet': 'drop', \n",
    "    'Session Idle (minutes)': 'drop', \n",
    "    'Space #': 'drop',\n",
    "    'Session start month':'drop', \n",
    "    'Session start day': 'drop', \n",
    "    'Session start hour': 'drop',\n",
    "    'Session start day of week': 'drop', \n",
    "    'Session start time': 'drop', \n",
    "    'Session end month': 'drop',\n",
    "    'Session end day': 'drop', \n",
    "    'Session end hour': 'drop', \n",
    "    'Session end day of week': 'drop',\n",
    "    'Session end time': 'drop'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns with value 'drop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [key for key, value in column_mapping.items() if value == 'drop']\n",
    "flexpoint_dropped = flexpoint.drop(columns=columns_to_drop, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the powerflex dataframe columns with the values from the dictionary, to make it compatible with the chargerpoint dataframe format.Additionally reorder columns in renamed flexpoint dataframe to match chargerpoint order. THis will also drop any columns left in flexpoint that are not present in chargerpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "flexpoint_renamed = flexpoint_dropped.rename(columns={k: v for k, v in column_mapping.items() if v != 'drop'})\n",
    "\n",
    "#flexpoint_renamed = flexpoint_renamed.reindex(charegerpoint.columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert minutes to timedelta\n",
    "flexpoint_renamed['Total Duration (hh:mm:ss)'] = pd.to_timedelta(flexpoint_renamed['Total Duration (hh:mm:ss)'], unit='m')\n",
    "\n",
    "# Assuming a base time at midnight of an arbitrary day\n",
    "base_time = pd.Timestamp('today').normalize()\n",
    "\n",
    "# Convert timedelta to time by adding to a base time and extracting time\n",
    "flexpoint_renamed['Total Duration (hh:mm:ss)'] = (base_time + flexpoint_renamed['Total Duration (hh:mm:ss)']).dt.time\n",
    "\n",
    "# Convert minutes to timedelta\n",
    "flexpoint_renamed['Charging Time (hh:mm:ss)'] = pd.to_timedelta(flexpoint_renamed['Charging Time (hh:mm:ss)'], unit='m')\n",
    "\n",
    "# Assuming a base time at midnight of an arbitrary day\n",
    "base_time = pd.Timestamp('today').normalize()\n",
    "\n",
    "# Convert timedelta to time by adding to a base time and extracting time\n",
    "flexpoint_renamed['Charging Time (hh:mm:ss)'] = (base_time + flexpoint_renamed['Charging Time (hh:mm:ss)']).dt.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally concatenate the two chargerpoint and flexpoint datframes and store complete and ready to work dataset in csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the two DataFrames\n",
    "combined_df = pd.concat([flexpoint_renamed, charegerpoint], ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "combined_df.to_csv('PALO_ALTO_dataset_compelete.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ba_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
